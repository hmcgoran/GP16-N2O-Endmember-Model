{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmcgoran/GP16-N2O-Endmember-Model/blob/main/Final_GP16_multiple_regression_Monte_Carlo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tf5IgSMui_uY"
      },
      "source": [
        "# Final GP16 Multiple Regression Overview (w/ Monte Carlo)\n",
        "This code uses an isotope mixing model adapted from Peters et al. 2018 which analyzed NO3- end members in the transect. The objective is to quantify the relative contributions of four N2O end members (background, AOA, incomplete denitrification (ID), and Oxygen Deficient Zone (ODZ)) in the GP16 transect. Broadly, the methodology involves defining the delta values of background N2O, AOA-produced N2O, ID-produced N2O, N2O produced in the ODZ, and a multiple linear least squares regression to estimate the relative contributions of each end member.\n",
        "\n",
        "The Colab is integrated with two Google Sheets: V4_COLAB Final GP16 Regression Model and V4_COLAB Water Mass Delta Definitions. If you want to run this code and make edits to the Colab, you should make a copy of the Colab + two sheets I linked above, and then update the links to the sheet in the Colab. The links needing change are distinguished in a section below using pound signs as follows:\n",
        "############################################################\n",
        "\n",
        "worksheet_name = gc.open_by_url('Google Sheet URL')\n",
        "\n",
        "worksheet_name = gc.open_by_url('Google Sheet URL')\n",
        "\n",
        "############################################################\n",
        "\n",
        "The Google Sheet URL can be obtained by clicking share > copy link in the Google Sheet.\n",
        "\n",
        "The code is based on data from GP16, meaning that all of the sheets referenced are also specific to GP16. To adapt this code to other cases, you would need to link different Google Sheets, change variable names, column names, and anything else that is specific to the region."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn6qYPobXkjU"
      },
      "source": [
        "# Logistics, Package Imports, Function Definitions, and Google Sheet Integration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEIov_ehm5lm"
      },
      "source": [
        "First, you will need to give Google Colab permission to access your Drive, which allows the formation of a live connection between Google Sheets and Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RiREwy2DOmf8"
      },
      "outputs": [],
      "source": [
        "######## Makes it possible to have a live connection between Google Sheets and Colab #######\n",
        "from google.colab import auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "\n",
        "# Authenticating to google\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJT-iq7IKvrh"
      },
      "source": [
        "The next two lines make it possible to import and export to the two Google Sheets mentioned in the overview.\n",
        "\n",
        "**IF YOU WANT TO RUN THIS COLAB ON YOUR OWN AND MAKE EDITS, CHANGE THESE TWO LINKS AS DESCRIBED IN THE OVERVIEW**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wN2J5Dl8KuzA"
      },
      "outputs": [],
      "source": [
        "######################################################################\n",
        "# Importing data live from the Google Sheets titled: \"V4_COLAB Monte Carlo Final GP16 Regression Model\"\n",
        "final_gp16_regression_model = gc.open_by_url(\n",
        "    'https://docs.google.com/spreadsheets/d/1wGER67HAfrxMDrzXcIlw4ojUQhGLtaZE8gq69vRj5hk/edit?usp=sharing')\n",
        "\n",
        "# Importing data live from the Google Sheets titled: \"V4_COLAB Monte Carlo Water Mass Delta Definitions\"\n",
        "water_mass_delta_definitions = gc.open_by_url(\n",
        "    'https://docs.google.com/spreadsheets/d/11q_4xOLxm7KRKdBoHDtBVJTJZviCswpKJ7uhs99acH4/edit?usp=sharing')\n",
        "######################################################################"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPRzld_BnSeJ"
      },
      "source": [
        "Next, the functions below need to be imported, some which are used throughout the Colab, and others that are only used once (i.e. csaps and cvxpy). This may take a minute or two, as some of the packages (gsw and csaps) need to be installed."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install gsw # For the potential density calculations\n",
        "import gsw as gsw\n",
        "!pip install csaps # For the cubic spline interpolation\n",
        "from csaps import csaps\n",
        "import matplotlib.pyplot as plt # For plotting\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "-zilZU7DyscL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoOrdjDEnuu_"
      },
      "source": [
        "The next section defines three functions that are frequently used throughout the colab. See the function descriptions in the comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUbJdPpjnRNM"
      },
      "outputs": [],
      "source": [
        "def import_sheet_as_df(worksheet_name, tab_name):\n",
        "  '''\n",
        "  Function that allows you to import sheets and values from\n",
        "  various Google Sheets tabs. tab_name should be entered as a string and\n",
        "  worksheet_name = gc.open_by_url('Google Sheet URL'), which should be defined\n",
        "  prior to calling this function.\n",
        "  '''\n",
        "  sheet = worksheet_name.worksheet(tab_name) # Obtains the tab/worksheet of interest from the main Google Sheet that is linked\n",
        "  rows = sheet.get_all_values() # get_all_values gives a list of rows\n",
        "  df = pd.DataFrame(rows[1:], columns=rows[0]) # Deletes the row numbers column and makes the first row the headers\n",
        "  return df\n",
        "\n",
        "def export_df_to_sheet(worksheet_name, new_tab_name, df_to_export):\n",
        "  '''\n",
        "  This function allows you to export a dataframe as a new tab in the Google\n",
        "  Sheet.  worksheet_name = gc.open_by_url('Google Sheet URL'),\n",
        "  new_tab_name is a string for what you want to call the new tab, df_to_export\n",
        "  is the dataframe you are exporting to the sheet\n",
        "  '''\n",
        "  new_sheet = worksheet_name.add_worksheet(new_tab_name, rows=400, cols = 85)\n",
        "  new_sheet.update([df_to_export.columns.values.tolist()] + df_to_export.values.tolist())\n",
        "\n",
        "def convert_column(dataframe, column_name):\n",
        "  '''\n",
        "  This function converts a column in a dataframe to a 1-D array.\n",
        "  There might be an easier way to do this, but I am not aware of it.\n",
        "  '''\n",
        "  prelim_list = list(dataframe[column_name])\n",
        "  variable_array = [float(i) for i in prelim_list]\n",
        "  return variable_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gVMuo5eX2iv"
      },
      "source": [
        "# Preliminary Data Processing and Merges"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwIBtx5rJ4OO"
      },
      "source": [
        "The following code then merges the N2O dataset, metadata, and water mass percentages into one big dataset by Sample ID. This is done through two merges. Potential density is calculated using the [gsw package](https://teos-10.github.io/GSW-Python/conversions.html) and added as a column to the dataframe before merging with the water mass data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AZQNCRijLHOn"
      },
      "outputs": [],
      "source": [
        "# Importing different tabs of the \"Final GP16 Regression Model\" Google Sheets as dataframes\n",
        "n2o = import_sheet_as_df(final_gp16_regression_model, \"GP16 N2O Data\")\n",
        "water_mass = import_sheet_as_df(final_gp16_regression_model, \"Water Mass Data\")\n",
        "\n",
        "# Merge N2O data with water mass data\n",
        "post_merge = pd.merge(n2o, water_mass, on='Sample ID')\n",
        "\n",
        "# The next line will export the merged data to Google Sheets under the tab \"Post-Merge Data Colab\"\n",
        "# You should comment the following line out if you don't need to export the data (i.e. if it is already there from a prior run)\n",
        "# export_df_to_sheet(final_gp16_regression_model, 'Post-Merge Data Colab', post_merge)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMecadFEkHe0"
      },
      "source": [
        "# Background N2O Definition\n",
        "Background N2O is the final term we use to describe preformed N2O, which is why \"pre\" is still used in this code and in the sheet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlfPL40s781i"
      },
      "source": [
        "## Background Definition - Import Intermediate + Deep Water Mass Definitions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9abjPde9s1GH"
      },
      "source": [
        "This section extracts all of the intermediate and deep water mass definitions from the Water Mass Delta Definitions Google Sheet and assigns them to variables for later use. If you change a value in the sheet, it will automatically update in the Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gAPdYtvkGI8"
      },
      "outputs": [],
      "source": [
        "inter_deep_def = import_sheet_as_df(water_mass_delta_definitions, \"Intermediate/Deep Definitions\")\n",
        "\n",
        "# NOTE: If you change a value in the sheet, it will automatically update when imported to Google Colab\n",
        "AAIW_N2O = inter_deep_def.loc[0]['[N2O]']\n",
        "EQPIW_N2O = inter_deep_def.loc[1]['[N2O]']\n",
        "UCDW_N2O = inter_deep_def.loc[2]['[N2O]']\n",
        "PDW_N2O = inter_deep_def.loc[3]['[N2O]']\n",
        "LCDW_N2O = inter_deep_def.loc[4]['[N2O]']\n",
        "AABW_N2O = inter_deep_def.loc[5]['[N2O]']\n",
        "\n",
        "AAIW_D15NA = inter_deep_def.loc[0]['d15Na']\n",
        "EQPIW_D15NA = inter_deep_def.loc[1]['d15Na']\n",
        "UCDW_D15NA = inter_deep_def.loc[2]['d15Na']\n",
        "PDW_D15NA = inter_deep_def.loc[3]['d15Na']\n",
        "LCDW_D15NA = inter_deep_def.loc[4]['d15Na']\n",
        "AABW_D15NA = inter_deep_def.loc[5]['d15Na']\n",
        "\n",
        "AAIW_D15NB = inter_deep_def.loc[0]['d15Nb']\n",
        "EQPIW_D15NB = inter_deep_def.loc[1]['d15Nb']\n",
        "UCDW_D15NB = inter_deep_def.loc[2]['d15Nb']\n",
        "PDW_D15NB = inter_deep_def.loc[3]['d15Nb']\n",
        "LCDW_D15NB = inter_deep_def.loc[4]['d15Nb']\n",
        "AABW_D15NB = inter_deep_def.loc[5]['d15Nb']\n",
        "\n",
        "AAIW_D18O = inter_deep_def.loc[0]['dO18']\n",
        "EQPIW_D18O = inter_deep_def.loc[1]['dO18']\n",
        "UCDW_D18O = inter_deep_def.loc[2]['dO18']\n",
        "PDW_D18O = inter_deep_def.loc[3]['dO18']\n",
        "LCDW_D18O = inter_deep_def.loc[4]['dO18']\n",
        "AABW_D18O = inter_deep_def.loc[5]['dO18']\n",
        "\n",
        "AAIW_O2 = inter_deep_def.loc[0]['O2']\n",
        "EQPIW_O2 = inter_deep_def.loc[1]['O2']\n",
        "UCDW_O2 = inter_deep_def.loc[2]['O2']\n",
        "PDW_O2 = inter_deep_def.loc[3]['O2']\n",
        "LCDW_O2 = inter_deep_def.loc[4]['O2']\n",
        "AABW_O2 = inter_deep_def.loc[5]['O2']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgUJ8xi9qm7I"
      },
      "source": [
        "## Background Definition - Import Thermocline Water Mass Definitions and Interpolate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzeSa4s-uaJg"
      },
      "source": [
        "In order to calculate the preformed delta values for each sample, we have to get a density-specific delta definition for each sample in the thermocline. This code imports the raw data that defines the three thermocline water masses (ESSW, ESPIW, and SPCW) from the Water Mass Delta Definitions Google Sheet. Then, the code interpolates the data using a cubic spline interpolation function (csaps package) between potential density 26-27 in 0.01 increments. If this is confusing, see the next section, which visualizes this code in plots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fMw8l-Gq6mz"
      },
      "outputs": [],
      "source": [
        "def univariate(dataframe, variable):\n",
        "  '''\n",
        "  This function takes the raw data for each N2O variable and\n",
        "  interpolates it over the 26-27 sigma theta range in 0.01 increments.\n",
        "  Eventually, these interpolated values are used to help calculate\n",
        "  preformed values. See https://csaps.readthedocs.io/en/latest/ for\n",
        "  documentation on the cubic spline approximation function. Currently,\n",
        "  a smoothing factor of 0.99 is used, however this number can be changed\n",
        "  to be more or less sensitive to changes in the raw data.\n",
        "  '''\n",
        "  x = np.linspace(26, 27, 100)  # Create 100 density values for interpolation\n",
        "  spline = csaps(dataframe[\"Density\"], dataframe[variable], x, smooth=0.99)\n",
        "  return spline\n",
        "\n",
        "# Imports the raw data for each of the three thermocline water masses\n",
        "essw = import_sheet_as_df(water_mass_delta_definitions, \"ESSW Definition\")\n",
        "espiw = import_sheet_as_df(water_mass_delta_definitions, \"ESPIW Definition\")\n",
        "spcw = import_sheet_as_df(water_mass_delta_definitions, \"SPCW Definition\")\n",
        "\n",
        "density = np.linspace(26, 27, 100) # Defines an array of \"x-values\" over which we want to interpolate\n",
        "espiw_df = pd.DataFrame(density, columns=['Density'])  # Create 100 row empty dataframe for interpolated values\n",
        "essw_df = pd.DataFrame(density, columns=['Density'])\n",
        "spcw_df = pd.DataFrame(density, columns=['Density'])\n",
        "\n",
        "variables = ['[N2O]', 'd15Na', 'd15Nb', 'd18O', 'd15Nbulk', 'SP', 'O2'] # Variables to interpolate\n",
        "for variable in variables:\n",
        "  espiw_df[variable] = univariate(espiw, variable) # Adds 100-point interpolation to the new dataframe for every variable\n",
        "  essw_df[variable] = univariate(essw, variable)\n",
        "  spcw_df[variable] = univariate(spcw, variable)\n",
        "\n",
        "espiw_df['Density'] = espiw_df['Density'].round(2) # Rounds the values to two decimal places\n",
        "essw_df['Density'] = essw_df['Density'].round(2)\n",
        "spcw_df['Density'] = spcw_df['Density'].round(2)\n",
        "\n",
        "print(espiw_df)\n",
        "print(essw_df)\n",
        "print(spcw_df)\n",
        "\n",
        "# export_df_to_sheet(water_mass_delta_definitions, 'ESSW Definitions Post-Interpolation (12/17)', essw_df)\n",
        "# export_df_to_sheet(water_mass_delta_definitions, 'ESPIW Definitions Post-Interpolation (12/17)', espiw_df)\n",
        "# export_df_to_sheet(water_mass_delta_definitions, 'SPCW Definitions Post-Interpolation (12/17)', spcw_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUGP2JD8xgUC"
      },
      "source": [
        "## Background Definition - Thermocline Interpolation and Profile Plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rRgDrasvSZT"
      },
      "source": [
        "This section visualizes what was done in the last section, where each thermocline water mass variable was interpolated from 26-27 sigma theta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5wqeVcYpunp"
      },
      "outputs": [],
      "source": [
        "def thermocline_plots(row, col, min, max, watermass_df, col_name, spline_df, var_label):\n",
        "  '''\n",
        "  This is a general function for plotting the interpolations and raw data values\n",
        "  for each water mass and each variable. Row = plot row, col = plot col,\n",
        "  min = x-axis minimum, max = x-axis maximum, watermass_df = imported dataframe\n",
        "  containing the raw values, col_name = the variable of interest, spline_df =\n",
        "  the dataframe that holds the interpolated value, var_label = name for the x-axis\n",
        "  '''\n",
        "  watermass_df[col_name] = watermass_df[col_name].astype(float) # Raw Data Values\n",
        "  watermass_df['Density'] = watermass_df['Density'].astype(float) # Density corresponding to raw data\n",
        "  ax[row, col].plot(watermass_df[col_name], watermass_df['Density'], 'bo', markersize=3)  # Plot original points\n",
        "  ax[row, col].plot(spline_df[col_name], spline_df['Density'], 'x-', c='orange', markersize=3)  # Plot spline\n",
        "  ax[row, col].set_xlim(min, max)\n",
        "  ax[row, col].set_ylabel('Potential Density')\n",
        "  ax[row, col].set_xlabel(var_label)\n",
        "\n",
        "fig, ax = plt.subplots(3, 5, sharey='row') # Make the y-axis the same for all rows\n",
        "fig.set_size_inches(14, 14) # Size of the panel\n",
        "fig.subplots_adjust(hspace = 0.3, wspace = 0.2) # Space between plots\n",
        "\n",
        "# ESSW Plots\n",
        "ax[0, 0].invert_yaxis()\n",
        "thermocline_plots(0, 0, 10, 65, essw, '[N2O]', essw_df, \"[N2O] ESSW\")\n",
        "thermocline_plots(0, 1, 40, 65, essw, 'd18O', essw_df, \"d18O ESSW\")\n",
        "thermocline_plots(0, 2, 7.5, 20, essw, 'd15Na', essw_df, \"d15Na ESSW\")\n",
        "thermocline_plots(0, 3, -4, 3, essw, 'd15Nb', essw_df, \"d15Nb ESSW\")\n",
        "thermocline_plots(0, 4, 0, 210, essw, 'O2', essw_df, \"O2 ESSW\")\n",
        "\n",
        "# ESPIW Plots\n",
        "ax[1, 0].invert_yaxis()\n",
        "thermocline_plots(1, 0, 10, 65, espiw, '[N2O]', espiw_df, \"[N2O] ESPIW\")\n",
        "thermocline_plots(1, 1, 40, 65, espiw, 'd18O', espiw_df, \"d18O ESPIW\")\n",
        "thermocline_plots(1, 2, 7.5, 20, espiw, 'd15Na', espiw_df, \"d15Na ESPIW\")\n",
        "thermocline_plots(1, 3, -4, 3, espiw, 'd15Nb', espiw_df, \"d15Nb ESPIW\")\n",
        "thermocline_plots(1, 4, 0, 210, espiw, 'O2', espiw_df, \"O2 ESPIW\")\n",
        "\n",
        "# SPCW Plots\n",
        "ax[2, 0].invert_yaxis()\n",
        "thermocline_plots(2, 0, 10, 65, spcw, '[N2O]', spcw_df, \"[N2O] SPCW\")\n",
        "thermocline_plots(2, 1, 40, 65, spcw, 'd18O', spcw_df, \"d18O SPCW\")\n",
        "thermocline_plots(2, 2, 7.5, 20, spcw, 'd15Na', spcw_df, \"d15Na SPCW\")\n",
        "thermocline_plots(2, 3, -4, 3, spcw, 'd15Nb', spcw_df, \"d15Nb SPCW\")\n",
        "thermocline_plots(2, 4, 0, 210, spcw, 'O2', spcw_df, \"O2 SPCW\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQt2O9X9xrED"
      },
      "source": [
        "## Background Definition - Calculate Sample-Specific Preformed Values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTevdgPUAF3r"
      },
      "source": [
        "This section takes all of the previously defined data to calculate sample-by-sample preformed d18O, d15Na, d15Nb, and O2. First, the water mass percentage values from Peters 2018 are imported as lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pF8PDyDBx1EP"
      },
      "outputs": [],
      "source": [
        "# post_merge = import_sheet_as_df(final_gp16_regression_model, \"Post-Merge Data Colab\")\n",
        "\n",
        "def water_mass_percent(column):\n",
        "  '''\n",
        "  This function takes the column of water percent values for the specified\n",
        "  water mass from the post-merge dataset and divides all values by 100\n",
        "  so that the percentages are converted to proportions and able to be\n",
        "  incorporated into the preformed calculation.\n",
        "  '''\n",
        "  pct_import = post_merge[column].tolist()\n",
        "  pct_list = [float(num) / 100 for num in pct_import] # Convert the proportions from Peters et al. 2018 to percentages\n",
        "  return pct_list\n",
        "\n",
        "essw_pct = water_mass_percent('ESSW_PCT')\n",
        "espiw_pct = water_mass_percent('ESPIW_PCT')\n",
        "spcw_pct = water_mass_percent('SPCW_PCT')\n",
        "aaiw_pct = water_mass_percent('AAIW_PCT')\n",
        "eqpiw_pct = water_mass_percent('EQPIW_PCT')\n",
        "ucdw_pct = water_mass_percent('UCDW_PCT')\n",
        "pdw_pct = water_mass_percent('PDW_PCT')\n",
        "lcdw_pct = water_mass_percent('LCDW_PCT')\n",
        "aabw_pct = water_mass_percent('AABW_PCT')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzILUA7a9C1Z"
      },
      "source": [
        "Next, isotope mass balance is used to calculate the preformed values for each sample using this equation: Σ over all water masses (water mass % * water mass definition * [N2O]) / Σ over all water masses (water mass % * [N2O])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzqg_oeW9A_C"
      },
      "outputs": [],
      "source": [
        "d18O_pre = [] # Set up empty lists to hold the calculated preformed values\n",
        "d15Na_pre = []\n",
        "d15Nb_pre = []\n",
        "o2_pre = []\n",
        "samp_density = post_merge['Potdens'].astype(float).round(2).tolist()\n",
        "\n",
        "for i in range(len(samp_density)): # Loops through every sample in the entire dataset\n",
        "  if 26 <= samp_density[i] <= 27: # If the sample is in the thermocline\n",
        "    row_espiw = espiw_df.loc[espiw_df['Density'] == samp_density[i]]  # Obtains the row from the espiw_df for the respective density\n",
        "    row_essw = essw_df.loc[essw_df['Density'] == samp_density[i]]\n",
        "    row_spcw = spcw_df.loc[spcw_df['Density'] == samp_density[i]]\n",
        "  else:\n",
        "    # If the sample density is not in the thermocline (26-27 sigma theta), then we make the values 0\n",
        "    row_espiw = pd.DataFrame(np.zeros((1,6)), columns = ['Density', '[N2O]', 'd15Na','d15Nb', 'd18O', 'O2'])\n",
        "    row_essw = pd.DataFrame(np.zeros((1,6)), columns = ['Density', '[N2O]', 'd15Na','d15Nb', 'd18O', 'O2'])\n",
        "    row_spcw = pd.DataFrame(np.zeros((1,6)), columns = ['Density', '[N2O]', 'd15Na','d15Nb', 'd18O', 'O2'])\n",
        "\n",
        "  # Calculate the denominator, which is just water mass percent * [N2O] all summed together\n",
        "  denominator = (\n",
        "    float(essw_pct[i]) * float(row_essw['[N2O]']) +\n",
        "    float(espiw_pct[i]) * float(row_espiw['[N2O]']) +\n",
        "    float(spcw_pct[i]) * float(row_spcw['[N2O]']) +\n",
        "    float(aaiw_pct[i]) * float(AAIW_N2O) +\n",
        "    float(eqpiw_pct[i]) * float(EQPIW_N2O) +\n",
        "    float(ucdw_pct[i]) * float(UCDW_N2O) +\n",
        "    float(pdw_pct[i]) * float(PDW_N2O) +\n",
        "    float(lcdw_pct[i]) * float(LCDW_N2O) +\n",
        "    float(aabw_pct[i]) * float(AABW_N2O)\n",
        "    )\n",
        "\n",
        "  # d18O preformed calculation for one sample\n",
        "  d18O_pre_calc = (\n",
        "    float(essw_pct[i]) * float(row_essw['[N2O]']) * float(row_essw['d18O']) +\n",
        "    float(espiw_pct[i]) * float(row_espiw['[N2O]']) * float(row_espiw['d18O']) +\n",
        "    float(spcw_pct[i]) * float(row_spcw['[N2O]']) * float(row_spcw['d18O']) +\n",
        "    float(aaiw_pct[i]) * float(AAIW_N2O) * float(AAIW_D18O) +\n",
        "    float(eqpiw_pct[i]) * float(EQPIW_N2O) * float(EQPIW_D18O) +\n",
        "    float(ucdw_pct[i]) * float(UCDW_N2O) * float(UCDW_D18O) +\n",
        "    float(pdw_pct[i]) * float(PDW_N2O) * float(PDW_D18O) +\n",
        "    float(lcdw_pct[i]) * float(LCDW_N2O) * float(LCDW_D18O) +\n",
        "    float(aabw_pct[i]) * float(AABW_N2O) * float(AABW_D18O)\n",
        "    ) / denominator\n",
        "  d18O_pre_calc = round(d18O_pre_calc, 2)\n",
        "  d18O_pre.append(d18O_pre_calc)\n",
        "\n",
        "  # d15Na preformed calculation for one sample\n",
        "  d15Na_pre_calc = (\n",
        "    float(essw_pct[i]) * float(row_essw['[N2O]']) * float(row_essw['d15Na']) +\n",
        "    float(espiw_pct[i]) * float(row_espiw['[N2O]']) * float(row_espiw['d15Na']) +\n",
        "    float(spcw_pct[i]) * float(row_spcw['[N2O]']) * float(row_spcw['d15Na']) +\n",
        "    float(aaiw_pct[i]) * float(AAIW_N2O) * float(AAIW_D15NA) +\n",
        "    float(eqpiw_pct[i]) * float(EQPIW_N2O) * float(EQPIW_D15NA) +\n",
        "    float(ucdw_pct[i]) * float(UCDW_N2O) * float(UCDW_D15NA) +\n",
        "    float(pdw_pct[i]) * float(PDW_N2O) * float(PDW_D15NA) +\n",
        "    float(lcdw_pct[i]) * float(LCDW_N2O) * float(LCDW_D15NA) +\n",
        "    float(aabw_pct[i]) * float(AABW_N2O) * float(AABW_D15NA)\n",
        "    ) / denominator\n",
        "  d15Na_pre_calc = round(d15Na_pre_calc, 2)\n",
        "  d15Na_pre.append(d15Na_pre_calc)\n",
        "\n",
        "  # d15Nb preformed calculation for one sample\n",
        "  d15Nb_pre_calc = (\n",
        "    float(essw_pct[i]) * float(row_essw['[N2O]']) * float(row_essw['d15Nb']) +\n",
        "    float(espiw_pct[i]) * float(row_espiw['[N2O]']) * float(row_espiw['d15Nb']) +\n",
        "    float(spcw_pct[i]) * float(row_spcw['[N2O]']) * float(row_spcw['d15Nb']) +\n",
        "    float(aaiw_pct[i]) * float(AAIW_N2O) * float(AAIW_D15NB) +\n",
        "    float(eqpiw_pct[i]) * float(EQPIW_N2O) * float(EQPIW_D15NB) +\n",
        "    float(ucdw_pct[i]) * float(UCDW_N2O) * float(UCDW_D15NB) +\n",
        "    float(pdw_pct[i]) * float(PDW_N2O) * float(PDW_D15NB) +\n",
        "    float(lcdw_pct[i]) * float(LCDW_N2O) * float(LCDW_D15NB) +\n",
        "    float(aabw_pct[i]) * float(AABW_N2O) * float(AABW_D15NB)\n",
        "    ) / denominator\n",
        "  d15Nb_pre_calc = round(d15Nb_pre_calc, 2)\n",
        "  d15Nb_pre.append(d15Nb_pre_calc)\n",
        "\n",
        "  # O2 preformed calculation for one sample\n",
        "  o2_pre_calc = (\n",
        "    float(essw_pct[i]) * float(row_essw['O2']) +\n",
        "    float(espiw_pct[i]) * float(row_espiw['O2']) +\n",
        "    float(spcw_pct[i]) * float(row_spcw['O2']) +\n",
        "    float(aaiw_pct[i]) * float(AAIW_O2) +\n",
        "    float(eqpiw_pct[i]) * float(EQPIW_O2) +\n",
        "    float(ucdw_pct[i]) * float(UCDW_O2) +\n",
        "    float(pdw_pct[i]) * float(PDW_O2)  +\n",
        "    float(lcdw_pct[i]) * float(LCDW_O2)  +\n",
        "    float(aabw_pct[i]) * float(AABW_O2)\n",
        "    )\n",
        "  o2_pre_calc = round(o2_pre_calc, 2)\n",
        "  o2_pre.append(o2_pre_calc)\n",
        "\n",
        "print(f\"Mean Preformed d18O: {round(sum(d18O_pre)/len(d18O_pre), 2)}\", \"\\n\"f\"Min/Max Preformed d18O: {min(d18O_pre)} to {max(d18O_pre)}\")\n",
        "print(f\"Preformed d18O Values: {d18O_pre}\")\n",
        "\n",
        "print(\"\\n\" f\"Mean Preformed d15Na: {round(sum(d15Na_pre)/len(d15Na_pre), 2)}\", \"\\n\"f\"Min/Max Preformed d15Na: {min(d15Na_pre)} to {max(d15Na_pre)}\")\n",
        "print(f\"Preformed d15Na Values: {d15Na_pre}\")\n",
        "\n",
        "print(\"\\n\" f\"Mean Preformed d15Nb: {round(sum(d15Nb_pre)/len(d15Nb_pre), 2)}\", \"\\n\"f\"Min/Max Preformed d15Nb: {min(d15Nb_pre)} to {max(d15Nb_pre)}\")\n",
        "print(f\"Preformed d15Nb Values: {d15Nb_pre}\")\n",
        "print(\"\\n\" f\"Preformed O2 Values: {o2_pre}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzd3y-EfgBdV"
      },
      "source": [
        "# Model Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqNS2KYRXxk8"
      },
      "source": [
        "To conduct the mathematical optimization, we must import the observed N2O data, and then subsequently define the AOA and ODZ N2O delta values as constants. See the paper for more detail on the AOA and ODZ definitions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xImZDAT5gDwK"
      },
      "outputs": [],
      "source": [
        "# Import observed data values\n",
        "n2o_obs =  post_merge['n2o_nm'].tolist()\n",
        "d18O_obs = post_merge['d18o'].tolist()\n",
        "d15Na_obs = post_merge['alpha'].tolist()\n",
        "d15Nb_obs = post_merge['beta'].tolist()\n",
        "\n",
        "########## AOA End Member Definition #############\n",
        "# From Santoro et al. 2021, corrected for substrate\n",
        "# D18O_AOA = 34.0 # Value as of April 2025\n",
        "# D18O_AOA = 46.0 # d18O value for sensitivity test\n",
        "# D18O_AOA =54.0 # d18O value for sensitivity test\n",
        "D15NA_AOA = 30.3\n",
        "D15NB_AOA = 0\n",
        "\n",
        "########## ID End Member Definition #############\n",
        "# Determine the ID definition based on GP16 NO3- data (point-by-point) and applied isotope effects\n",
        "d18o_no3 = post_merge['d18O-NO3 AVG (FINAL)'].tolist()\n",
        "d15n_no3 = post_merge['d15N-NO3 AVG (FINAL)'].tolist()\n",
        "\n",
        "print(f\"D18O NO3- : {d18o_no3}\")\n",
        "print(f\"D15Nbulk NO3- : {d15n_no3}\")\n",
        "\n",
        "d18o_id = np.array(d18o_no3, dtype=float) + 36\n",
        "d15na_id = np.array(d15n_no3, dtype=float) - 0\n",
        "d15nb_id = np.array(d15n_no3, dtype=float) - 22\n",
        "# d15na_id = np.array(d15n_no3, dtype=float) - 10 # d15na_id for sensitivity test\n",
        "# d15nb_id = np.array(d15n_no3, dtype=float) - 10 # d15nb_id for sensitivity test\n",
        "print(\"\\n\" f\"D18O ID Definition: {d18o_id}\")\n",
        "print(f\"D15NA ID Definition: {d15na_id}\")\n",
        "print(f\"D15NB ID Definition: {d15nb_id}\")\n",
        "\n",
        "########## CD End Member Definition #####################\n",
        "# Determine the CD definition based on collected data\n",
        "odz_n2o = post_merge[(post_merge['OXYGEN'].astype(float) < 5) & (post_merge['Potdens'].astype(float) > 26.2) & (post_merge['Potdens'].astype(float) < 26.8)]\n",
        "D18O_CD = (sum(odz_n2o['d18o'].astype(float) * odz_n2o['n2o_nm'].astype(float))) / sum(odz_n2o['n2o_nm'].astype(float))\n",
        "D18O_SD_CD = np.sqrt((sum((odz_n2o['d18o'].astype(float)-D18O_CD)**2 * odz_n2o['n2o_nm'].astype(float)))\n",
        "                      / ((len(odz_n2o['n2o_nm'])-1) * sum(odz_n2o['n2o_nm'].astype(float)) / len(odz_n2o['n2o_nm'])))\n",
        "\n",
        "D15NA_CD = (sum(odz_n2o['alpha'].astype(float) * odz_n2o['n2o_nm'].astype(float))) / sum(odz_n2o['n2o_nm'].astype(float))\n",
        "D15NA_SD_CD = np.sqrt((sum((odz_n2o['alpha'].astype(float)-D15NA_CD)**2 * odz_n2o['n2o_nm'].astype(float)))\n",
        "                      / ((len(odz_n2o['n2o_nm'])-1) * sum(odz_n2o['n2o_nm'].astype(float)) / len(odz_n2o['n2o_nm'])))\n",
        "\n",
        "D15NB_CD = (sum(odz_n2o['beta'].astype(float) * odz_n2o['n2o_nm'].astype(float))) / sum(odz_n2o['n2o_nm'].astype(float))\n",
        "D15NB_SD_CD = np.sqrt((sum((odz_n2o['beta'].astype(float)-D15NB_CD)**2 * odz_n2o['n2o_nm'].astype(float)))\n",
        "                      / ((len(odz_n2o['n2o_nm'])-1) * sum(odz_n2o['n2o_nm'].astype(float)) / len(odz_n2o['n2o_nm'])))\n",
        "\n",
        "print(\"\\n\" f\"D18O CD Definition: {str(round(D18O_CD, 2))}, std({str(round(D18O_SD_CD, 2))})\")\n",
        "print(f\"D15NA CD Definition: {str(round(D15NA_CD, 2))}, std({str(round(D15NA_SD_CD, 2))})\")\n",
        "print(f\"D15NB CD Definition: {str(round(D15NB_CD, 2))}, std({str(round(D15NB_SD_CD, 2))})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HJ19rXU9-FU"
      },
      "source": [
        "At this point, we now have all the necessary data to apply the multiple linear least squares regression function. The operations carried out below are from the CVXPY package documented here: https://www.cvxpy.org/. The least squares function allows you to constrain the variables to be positive and sum to 1, as shown in the code below. Setting this constraint (along with the constraint that the coefficients have to be positive) ensures that we can appropriately account for all of the N2O concentration at each point. Using a least squares function that does not constrain the coefficients to sum to one leads to high residual concentrations and unintuitive results (more on this in the write-up)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "NDcQmaUkQbZV"
      },
      "outputs": [],
      "source": [
        "# CVXPY 1.4\n",
        "!pip install cvxpy==1.6\n",
        "import cvxpy as cp\n",
        "!pip show cvxpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_lLKHtS99KS"
      },
      "outputs": [],
      "source": [
        "# Create empty dataframe to store results\n",
        "ratios = pd.DataFrame(columns = ['Preformed Ratio', 'AOA Ratio', 'ID Ratio', 'CD Ratio'])\n",
        "\n",
        "for i in range(len(n2o_obs)):\n",
        "  A = np.array([[d15Na_pre[i], D15NA_AOA, d15na_id[i], D15NA_CD], [d15Nb_pre[i], D15NB_AOA, d15nb_id[i], D15NB_CD], [d18O_pre[i], D18O_AOA, d18o_id[i], D18O_CD]])\n",
        "  b = np.array([d15Na_obs[i], d15Nb_obs[i], d18O_obs[i]])\n",
        "\n",
        "  x = cp.Variable(4, nonneg=True) # Number of coefficients that are being guessed, also equal to number of rows in A\n",
        "  objective = cp.Minimize(cp.sum_squares(A @ x-b)) # Minimizes the sum of the squares to optimize the coefficient guess\n",
        "  constraints = [cp.sum(x) == 1] # Constrains the coefficient predictions to be >= 0 and sum to 1\n",
        "  prob  = cp.Problem(objective, constraints)\n",
        "  result = prob.solve()\n",
        "\n",
        "  ratios_to_df = pd.DataFrame([x.value], columns = ratios.columns)\n",
        "  ratios = pd.concat([ratios, ratios_to_df], ignore_index = True) # Appends new sample onto dataframe\n",
        "\n",
        "print(ratios) # The ratios variable holds the result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZQn437MoCS_"
      },
      "source": [
        "# Monte Carlo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2eaLU-xlN-1"
      },
      "source": [
        "## Monte Carlo that bypasses cases when CVXPY fails"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbEBpsgAgmgO"
      },
      "outputs": [],
      "source": [
        "# Monte Carlo to Catch Exceptions\n",
        "def montecarlo_w_except(n, post_merge,\n",
        "                              D18O_AOA, D15NA_AOA, D15NB_AOA,\n",
        "                              d18o_id, d15na_id, d15nb_id,\n",
        "                              D18O_CD, D18O_CD_SD, D15NA_CD, D15NA_CD_SD, D15NB_CD, D15NB_CD_SD):\n",
        "      \"\"\"\n",
        "      Function montecarlo_w_except inputs:\n",
        "      n = number of Monte Carlo iterations\n",
        "      post_merge = growing dataframe of observed and other compiled data\n",
        "      D18O_AOA = D18O AOA Definition\n",
        "      D15NA_AOA = D15NA AOA Definition\n",
        "      D15NB_AOA = D15NB AOA Definition\n",
        "\n",
        "      d18o_id = D18O ID Definition\n",
        "      d15na_id = D15NA ID Definition\n",
        "      d15nb_id = D15NB ID Definition\n",
        "\n",
        "      D18O_CD = D18O CD Definition\n",
        "      D18O_CD_SD = D18O CD Definition Standard Deviation\n",
        "      D15NA_CD = D15NA CD Definition\n",
        "      D15NA_CD_SD = D15NA CD Definition Standard Deviation\n",
        "      D15NB_CD = D15NB CD Definition\n",
        "      D15NB_CD_SD = D15NB CD Definition Standard Deviation\n",
        "\n",
        "      Function runs a Monte Carlo simulation varying the ODZ end member by generating random parameter values from a normal\n",
        "      distribution defined by the respective standard deviations. Accounts for cases in which\n",
        "      the solver is unable to obtain a solution for the given parameters. Returns the average\n",
        "      standard deviation for each of the four end members as well as the average standard deviation\n",
        "      for each sample. Originally, we were going to vary all four end members; however, to avoid propogating\n",
        "      more error than necessary we eventually limited the variation to the complete denitrification/ODZ/partial\n",
        "      consumption) end members.\n",
        "      \"\"\"\n",
        "      # Initialize four empty arrays that will hold the end member ratio results for each Monte Carlo iteration\n",
        "      pre_array = np.empty((len(post_merge[\"n2o_nm\"]), 0))\n",
        "      aoa_array = np.empty((len(post_merge[\"n2o_nm\"]), 0))\n",
        "      id_array = np.empty((len(post_merge[\"n2o_nm\"]), 0))\n",
        "      cd_array = np.empty((len(post_merge[\"n2o_nm\"]), 0))\n",
        "      rand_parameters = np.empty((3, 0))\n",
        "\n",
        "      iterations = 0 # Count how many successful iterations there are within n iterations\n",
        "\n",
        "      for i in range(n): # loop through n Monte Carlo iterations\n",
        "          # Generate perturbed CD definitions for this particular MC iteration\n",
        "          d18o_cd_perturb = np.random.normal(D18O_CD, D18O_CD_SD)\n",
        "          d15na_cd_perturb = np.random.normal(D15NA_CD, D15NA_CD_SD)\n",
        "          d15nb_cd_perturb = np.random.normal(D15NB_CD, D15NB_CD_SD)\n",
        "\n",
        "          # To store the results from this specific iteration\n",
        "          parameters_i = [d18o_cd_perturb, d15na_cd_perturb, d15nb_cd_perturb]\n",
        "          pre_array_column_i = []\n",
        "          aoa_array_column_i = []\n",
        "          id_array_column_i = []\n",
        "          cd_array_column_i = []\n",
        "\n",
        "          crashed = False # Set crashed = False to use as a conditional statement later on\n",
        "          for samp_num in range(len(post_merge[\"n2o_nm\"])): # Looping through all the collected samples for one Monte Carlo iteration\n",
        "                try: # Attempt to solve the optimization problem\n",
        "                    A = np.array([[d15Na_pre[samp_num], D15NA_AOA, d15na_id[samp_num], d15na_cd_perturb],\n",
        "                                  [d15Nb_pre[samp_num], D15NB_AOA, d15nb_id[samp_num], d15nb_cd_perturb],\n",
        "                                  [d18O_pre[samp_num], D18O_AOA, d18o_id[samp_num], d18o_cd_perturb]])\n",
        "                    b = np.array([d15Na_obs[samp_num], d15Nb_obs[samp_num], d18O_obs[samp_num]])\n",
        "\n",
        "                    x = cp.Variable(4, nonneg=True) # Number of coefficients, also equal to number of rows in A\n",
        "                    objective = cp.Minimize(cp.sum_squares(A @ x-b)) # Minimizes the sum of the squares to optimize the coefficient guess\n",
        "                    constraints = [cp.sum(x) == 1] # Constrains the coefficient predictions to be >= 0 and sum to 1\n",
        "                    prob  = cp.Problem(objective, constraints)\n",
        "                    result = prob.solve()\n",
        "\n",
        "                    # Add the new result to their respective arrays\n",
        "                    pre_array_column_i = np.append(pre_array_column_i, x.value[0])\n",
        "                    aoa_array_column_i = np.append(aoa_array_column_i, x.value[1])\n",
        "                    id_array_column_i = np.append(id_array_column_i, x.value[2])\n",
        "                    cd_array_column_i = np.append(cd_array_column_i, x.value[3])\n",
        "\n",
        "                except cp.SolverError as e: # If there is a Solver Error, print an error message, set crashed = True, terminate current for loop and move on to next Monte Carlo simulation with new parameters\n",
        "                    print(f\"Solver failed during iteration {i}, \\n sample {samp_num}, \\n d15Na_obs {d15Na_obs[samp_num]}, \\n d15Na_pre {d15Na_pre[samp_num]}, \\n d15Na_id {d15na_id[samp_num]}, \\n d15Na_pc {d15na_cd_perturb}, \\n d15Nb_obs {d15Nb_obs[samp_num]}, \\n d15Nb_pre {d15Nb_pre[samp_num]}, \\n d15Nb_id {d15nb_id[samp_num]}, \\n d15Nb_pc {d15nb_cd_perturb}, \\n d18O_obs {d18O_obs[samp_num]}, \\n d18O_pre {d18O_pre[samp_num]}, \\n d18O_id {d18o_id[samp_num]}, \\n d18O_pc {d18o_cd_perturb} \\n {e}\")\n",
        "                    crashed = True\n",
        "                    break\n",
        "\n",
        "          if not crashed and iterations < 1000: # If the given MC iteration was successful, add new column of ratios onto growing array of MC iteration results\n",
        "            iterations += 1\n",
        "            rand_parameters = np.column_stack((rand_parameters, parameters_i))\n",
        "            pre_array = np.column_stack((pre_array, pre_array_column_i))\n",
        "            aoa_array = np.column_stack((aoa_array, aoa_array_column_i))\n",
        "            id_array = np.column_stack((id_array, id_array_column_i))\n",
        "            cd_array = np.column_stack((cd_array, cd_array_column_i))\n",
        "\n",
        "      # Export MC ratios for each end member to Google Sheets and remember to change the sheet number to export\n",
        "      export_df_to_sheet(final_gp16_regression_model, 'MC Parameters 10', pd.DataFrame(rand_parameters, columns=[\"Random Parameters\"] * (iterations)))\n",
        "      export_df_to_sheet(final_gp16_regression_model, 'MC Pre Array 10', pd.DataFrame(pre_array, columns=[\"Pre Iteration Ratio\"] * (iterations)))\n",
        "      export_df_to_sheet(final_gp16_regression_model, 'MC AOA Array 10', pd.DataFrame(aoa_array, columns=[\"AOA Iteration Ratio\"] * (iterations)))\n",
        "      export_df_to_sheet(final_gp16_regression_model, 'MC ID Array 10', pd.DataFrame(id_array, columns=[\"ID Iteration Ratio\"] * (iterations)))\n",
        "      export_df_to_sheet(final_gp16_regression_model, 'MC CD Array 10', pd.DataFrame(cd_array, columns=[\"CD Iteration Ratio\"] * (iterations)))\n",
        "\n",
        "      pre_stdevs = np.std(pre_array, axis = 1) # Take standard deviations of every row (which corresponds to a standard deviation for each sample)\n",
        "      aoa_stdevs = np.std(aoa_array, axis = 1)\n",
        "      id_stdevs = np.std(id_array, axis = 1)\n",
        "      cd_stdevs = np.std(cd_array, axis = 1)\n",
        "\n",
        "      pre_array_stdev = np.mean(pre_stdevs) # Find average standard deviation for each end member\n",
        "      aoa_array_stdev = np.mean(aoa_stdevs)\n",
        "      id_array_stdev = np.mean(id_stdevs)\n",
        "      cd_array_stdev = np.mean(cd_stdevs)\n",
        "\n",
        "      print(f\"Successful Iterations: {iterations}\")\n",
        "      print(f\"Average Preformed Ratio Standard Deviation: {pre_array_stdev}\")\n",
        "      print(f\"Average AOA Ratio Standard Deviation: {aoa_array_stdev}\")\n",
        "      print(f\"Average Incomplete Denitrification Ratio Standard Deviation: {id_array_stdev}\")\n",
        "      print(f\"Average Partial Consumption Ratio Standard Deviation: {cd_array_stdev}\")\n",
        "\n",
        "      return pre_stdevs, aoa_stdevs, id_stdevs, cd_stdevs, pre_array_stdev, aoa_array_stdev, id_array_stdev, cd_array_stdev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBIXO8U6uts_"
      },
      "outputs": [],
      "source": [
        "# Monte Carlo perturbing only ID and CD and d18O AOA at 46\n",
        "# D18O_AOA = 46.0  # Currently have added 12 to account for 18O of oxygen in deep ocean\n",
        "D18O_AOA = 34.0  # Currently have added 12 to account for 18O of oxygen in deep ocean\n",
        "D18O_AOA_SD = 0.9 # Standard deviations of original measurements\n",
        "D15NA_AOA = 30.3\n",
        "D15NA_AOA_SD = 1.6\n",
        "D15NB_AOA = 0\n",
        "D15NB_AOA_SD = 1.6\n",
        "\n",
        "D18O_CD = 70.21\n",
        "D18O_CD_SD = 9.41\n",
        "D15NA_CD = 23.96\n",
        "D15NA_CD_SD = 6.72\n",
        "D15NB_CD = -2.08\n",
        "D15NB_CD_SD = 3.39\n",
        "\n",
        "[pre_stdevs, aoa_stdevs, id_stdevs, cd_stdevs, pre_array_stdev, aoa_array_stdev, id_array_stdev, cd_array_stdev] = montecarlo_w_except(1020, post_merge,\n",
        "                           D18O_AOA, D15NA_AOA, D15NB_AOA,\n",
        "                           d18o_id, d15na_id, d15nb_id,\n",
        "                           D18O_CD, D18O_CD_SD, D15NA_CD, D15NA_CD_SD, D15NB_CD, D15NB_CD_SD)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg_d0yMOcfXf"
      },
      "source": [
        "# Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oiw5DVOeMHPc"
      },
      "source": [
        "Below are two ways of validating the results. The first is a back-calculation of the delta values, which uses the ratios outputted by the mathematical function and the original pre, prod, and ODZ delta definitions to back-calculate a delta value for the sample to see how close the prediction is from the observed value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNRqGqcGciAo"
      },
      "outputs": [],
      "source": [
        "# Back-Calculating the Delta Values\n",
        "pre_ratios = list(ratios['Preformed Ratio'])\n",
        "aoa_ratios = list(ratios['AOA Ratio'])\n",
        "id_ratios = list(ratios['ID Ratio'])\n",
        "cd_ratios = list(ratios['CD Ratio'])\n",
        "\n",
        "d18O_backcalc = []\n",
        "d15Na_backcalc = []\n",
        "d15Nb_backcalc = []\n",
        "d18O_errors = []\n",
        "d15Na_errors = []\n",
        "d15Nb_errors = []\n",
        "\n",
        "for i in range(len(pre_ratios)):\n",
        "  # Back-calculate the three delta values\n",
        "  d18O_predict = pre_ratios[i] * d18O_pre[i] + aoa_ratios[i] * D18O_AOA + id_ratios[i] * d18o_id[i] + cd_ratios[i] * D18O_CD\n",
        "  d15Na_predict = pre_ratios[i] * d15Na_pre[i] + aoa_ratios[i] * D15NA_AOA + id_ratios[i] * d15na_id[i] + cd_ratios[i] * D15NA_CD\n",
        "  d15Nb_predict = pre_ratios[i] * d15Nb_pre[i] + aoa_ratios[i] * D15NB_AOA + id_ratios[i] * d15nb_id[i] + cd_ratios[i] * D15NB_CD\n",
        "\n",
        "  # Find the difference between the back-calculation and the observed value\n",
        "  d18O_error = float(d18O_obs[i]) - d18O_predict\n",
        "  d15Na_error = float(d15Na_obs[i]) - d15Na_predict\n",
        "  d15Nb_error = float(d15Nb_obs[i]) - d15Nb_predict\n",
        "\n",
        "  d18O_backcalc.append(d18O_predict) # Append the back-calculation to the back-calculation list\n",
        "  d15Na_backcalc.append(d15Na_predict)\n",
        "  d15Nb_backcalc.append(d15Nb_predict)\n",
        "\n",
        "  d18O_errors.append(d18O_error) # Append the error to the error list\n",
        "  d15Na_errors.append(d15Na_error)\n",
        "  d15Nb_errors.append(d15Nb_error)\n",
        "\n",
        "print(f\"d18O Back-Calculation Errors: {d18O_errors}\")\n",
        "print(f\"d15Na Back-Calculation Errors: {d15Na_errors}\")\n",
        "print(f\"d15Nb Back-Calculation Errors: {d15Nb_errors}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_HEqs1m_ToA"
      },
      "source": [
        "The second validation approach is to evaluate the relationship between consumed oxygen and the model's estimation of produced N2O. If performing properly, we would expect the relationship to be positive. Consumed oxygen is defined as preformed O2 (which is calculated) - observed O2. The plots are shown below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMiasaeW8_7q"
      },
      "outputs": [],
      "source": [
        "# Consumed O2 vs Produced N2O Plots\n",
        "consumed_o2 = np.array(o2_pre) - post_merge['OXYGEN'].astype(float)\n",
        "fig, ax = plt.subplots(1, 2) # Make two plots\n",
        "fig.set_size_inches(7, 3) # Size of the panel\n",
        "fig.subplots_adjust(hspace = 0.5, wspace = 0.2) # Space between plots\n",
        "\n",
        "ax[0].plot(consumed_o2, aoa_ratios, 'bo', markersize=3)  # Plot original points\n",
        "ax[0].set_ylabel('AOA Produced N2O Ratio')\n",
        "ax[0].set_xlabel('O2 Consumed (umol/L)')\n",
        "\n",
        "n2o_obs = [float(num) for num in n2o_obs]\n",
        "ax[1].plot(consumed_o2, (np.array(aoa_ratios) * n2o_obs), 'bo', markersize=3)  # Plot original points\n",
        "ax[1].set_ylabel('AOA Produced [N2O]')\n",
        "ax[1].set_xlabel('O2 Consumed (umol/L)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLel9RPnlQhW"
      },
      "source": [
        "# Export Model Results and Validation Results to Google Sheets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_JMNmQN_50X"
      },
      "source": [
        "Lastly, because new data was generated through all of the above code, this section appends the new data onto the merged dataframe from the start as columns. Finally, this new dataframe is exported as a new tab to the main Google Sheet.\n",
        "\n",
        "**Remember to change the name of the new tab to be created in the last line of this section, otherwise you will get an error because the tab already exists.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0DRJO0QIewny"
      },
      "outputs": [],
      "source": [
        "# Add all new data to growing dataframe (post_merge), export to Google Sheets at the end\n",
        "n2o_obs = np.array(n2o_obs, dtype=np.float32)\n",
        "post_merge['Preformed Conc'] = np.array(pre_ratios) * n2o_obs\n",
        "post_merge['AOA Conc'] = np.array(aoa_ratios) * n2o_obs\n",
        "post_merge['ID Conc'] = np.array(id_ratios) * n2o_obs\n",
        "post_merge['ODZ Conc'] = np.array(cd_ratios) * n2o_obs\n",
        "post_merge['Preformed d18O'] = d18O_pre\n",
        "post_merge['Preformed d15Na'] = d15Na_pre\n",
        "post_merge['Preformed d15Nb'] = d15Nb_pre\n",
        "post_merge['Preformed O2'] = o2_pre\n",
        "post_merge['Consumed O2'] = consumed_o2\n",
        "post_merge['Preformed Ratio'] = pre_ratios\n",
        "post_merge['AOA Ratio'] = aoa_ratios\n",
        "post_merge['ID Ratio'] = id_ratios\n",
        "post_merge['ODZ Ratio'] = cd_ratios\n",
        "post_merge['Residual N2O'] = n2o_obs - (pre_ratios * n2o_obs + aoa_ratios * n2o_obs + id_ratios * n2o_obs + cd_ratios * n2o_obs)\n",
        "post_merge['d18O Back Calc'] = d18O_backcalc\n",
        "post_merge['d15Na Back Calc'] = d15Na_backcalc\n",
        "post_merge['d15Nb Back Calc'] = d15Nb_backcalc\n",
        "post_merge['d18O Back Calc Error'] = d18O_errors\n",
        "post_merge['d15Na Back Calc Error'] = d15Na_errors\n",
        "post_merge['d15Nb Back Calc Error'] = d15Nb_errors\n",
        "\n",
        "# post_merge['Preformed Mean Stdev'] = pre_stdevs\n",
        "# post_merge['AOA Mean Stdev'] = aoa_stdevs\n",
        "# post_merge['ID Mean Stdev'] = id_stdevs\n",
        "# post_merge['CD Mean Stdev'] = cd_stdevs\n",
        "\n",
        "# post_merge['Preformed Ratio + Mean Stdev'] = pre_stdevs + pre_ratios\n",
        "# post_merge['AOA Ratio + Mean Stdev'] = aoa_stdevs + aoa_ratios\n",
        "# post_merge['ID Ratio + Mean Stdev'] = id_stdevs + id_ratios\n",
        "# post_merge['CD Ratio + Mean Stdev'] = cd_stdevs + cd_ratios\n",
        "\n",
        "# post_merge['Preformed Ratio - Mean Stdev'] = pre_ratios - pre_stdevs\n",
        "# post_merge['AOA Ratio - Mean Stdev'] = aoa_ratios - aoa_stdevs\n",
        "# post_merge['ID Ratio - Mean Stdev'] = id_ratios - id_stdevs\n",
        "# post_merge['CD Ratio - Mean Stdev'] = cd_ratios - cd_stdevs\n",
        "\n",
        "# Change the sheet name to export\n",
        "export_df_to_sheet(final_gp16_regression_model, '11 Final Product Colab', post_merge)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXvKhcV7lK9z"
      },
      "source": [
        "# Plotting Results\n",
        "Plotting results interpolated over density and longitude\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXqEubugdgKR"
      },
      "outputs": [],
      "source": [
        "# MAIN FIGURE IN PAPER\n",
        "# Center is base case, two sides are base case +/- mean state\n",
        "mc_sheet = import_sheet_as_df(final_gp16_regression_model, \"10 Final Product Colab\")\n",
        "odz_n2o = mc_sheet[(mc_sheet['OXYGEN'].astype(float) < 5) & (mc_sheet['Potdens'].astype(float) > 26.2) & (mc_sheet['Potdens'].astype(float) < 26.8)]\n",
        "\n",
        "from matplotlib import tri\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.colab import files\n",
        "\n",
        "# NORMALIZE DATA BEFORE TRIANGULATION\n",
        "scaler = MinMaxScaler()\n",
        "scaled_long = scaler.fit_transform(mc_sheet['LONGITUDE_x'].astype(float).values.reshape(-1,1))\n",
        "scaled_depth = scaler.fit_transform(mc_sheet['Potdens'].astype(float).values.reshape(-1,1))\n",
        "\n",
        "triang=tri.Triangulation(scaled_long.flatten(), scaled_depth.flatten())\n",
        "triang_analyze=tri.TriAnalyzer(triang)\n",
        "mask=triang_analyze.get_flat_tri_mask()\n",
        "triang.set_mask(mask)\n",
        "\n",
        "def mc_plot(plot_name, variable, plot_row, plot_column):\n",
        "  cntr2 = ax[plot_row,plot_column].tricontourf(mc_sheet['LONGITUDE_x'].astype(float),mc_sheet['Potdens'].astype(float),mc_sheet[variable].astype(float), triangles=triang.triangles, mask=triang.mask,levels=np.linspace(-0.35,1.35,51,endpoint=True), extend=\"neither\", cmap=\"rainbow\", vmin=-0.35, vmax=1.35, fontsize=15)\n",
        "  # colorbar = fig.colorbar(cntr2, ax=ax[plot_row,plot_column])\n",
        "  # colorbar.ax.tick_params(labelsize=11)\n",
        "\n",
        "  dens_cntr = ax[plot_row,plot_column].tricontour(mc_sheet['LONGITUDE_x'].astype(float),mc_sheet['Potdens'].astype(float),mc_sheet['Potdens'].astype(float), linewidths=0.5, triangles=triang.triangles, mask=triang.mask,levels=[27, 27.72], colors = \"black\")\n",
        "  ax[plot_row,plot_column].plot(mc_sheet['LONGITUDE_x'].astype(float), mc_sheet['Potdens'].astype(float), 'ko', markersize=0.5)\n",
        "  ax[plot_row,plot_column].plot(odz_n2o['LONGITUDE_x'].astype(float), odz_n2o['Potdens'].astype(float), 'wx', markersize=2)\n",
        "  ax[plot_row,plot_column].clabel(dens_cntr, inline=True, fontsize=6, manual=[(-124, 27), (-124, 27.72)])\n",
        "\n",
        "  ax[plot_row,plot_column].set(xlim=(-153, -77), ylim=(26, 28))\n",
        "  ax[plot_row,plot_column].invert_yaxis()\n",
        "  ax[plot_row,plot_column].set_xlabel(\"Longitude (degrees)\", fontsize=10)\n",
        "  ax[plot_row, plot_column].set_ylabel(r\"$\\sigma_{\\Theta}$\", fontsize=10)\n",
        "  ax[plot_row,plot_column].set_title(plot_name, fontsize = 10)\n",
        "  return cntr2\n",
        "\n",
        "fig, ax = plt.subplots(4, 3) # Make twelve plots\n",
        "fig.set_size_inches(13.5, 7.5) # Size of the panel\n",
        "fig.subplots_adjust(hspace = 0.8, wspace = 0.5) # Space between plots\n",
        "\n",
        "mc_plot(\"$\\mathrm{N_2O_{background}}$ - Mean Stdev\", \"Preformed Ratio - Mean Stdev\", 0, 0)\n",
        "mc_plot(\"$\\mathrm{N_2O_{background}}$\", \"Preformed Ratio\", 0, 1)\n",
        "mc_plot(\"$\\mathrm{N_2O_{background}}$ + Mean Stdev\", \"Preformed Ratio + Mean Stdev\", 0, 2)\n",
        "\n",
        "mc_plot(\"$\\mathrm{N_2O_{AOA}}$ - Mean Stdev\", \"AOA Ratio - Mean Stdev\", 1, 0)\n",
        "mc_plot(\"$\\mathrm{N_2O_{AOA}}$\", \"AOA Ratio\", 1, 1)\n",
        "mc_plot(\"$\\mathrm{N_2O_{AOA}}$ + Mean Stdev\", \"AOA Ratio + Mean Stdev\", 1, 2)\n",
        "\n",
        "mc_plot(\"$\\mathrm{N_2O_{ID}}$ - Mean Stdev\", \"ID Ratio - Mean Stdev\", 2, 0)\n",
        "mc_plot(\"$\\mathrm{N_2O_{ID}}$\", \"ID Ratio\", 2, 1)\n",
        "mc_plot(\"$\\mathrm{N_2O_{ID}}$ + Mean Stdev\", \"ID Ratio + Mean Stdev\", 2, 2)\n",
        "\n",
        "mc_plot(\"$\\mathrm{N_2O_{ODZ}}$ - Mean Stdev\", \"CD Ratio - Mean Stdev\", 3, 0)\n",
        "mc_plot(\"$\\mathrm{N_2O_{ODZ}}$\", \"ODZ Ratio\", 3, 1)\n",
        "cntr2_4 = mc_plot(\"$\\mathrm{N_2O_{ODZ}}$ + Mean Stdev\", \"CD Ratio + Mean Stdev\", 3, 2)\n",
        "\n",
        "ax[0, 0].text(-0.2, 1.21, 'A1.', transform=ax[0, 0].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[0, 1].text(-0.2, 1.21, 'B1.', transform=ax[0, 1].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[0, 2].text(-0.2, 1.21, 'C1.', transform=ax[0, 2].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[1, 0].text(-0.2, 1.21, 'A2.', transform=ax[1, 0].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[1, 1].text(-0.2, 1.21, 'B2.', transform=ax[1, 1].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[1, 2].text(-0.2, 1.21, 'C2.', transform=ax[1, 2].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[2, 0].text(-0.2, 1.21, 'A3.', transform=ax[2, 0].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[2, 1].text(-0.2, 1.21, 'B3.', transform=ax[2, 1].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[2, 2].text(-0.2, 1.21, 'C3.', transform=ax[2, 2].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[3, 0].text(-0.2, 1.21, 'A4.', transform=ax[3, 0].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[3, 1].text(-0.2, 1.21, 'B4.', transform=ax[3, 1].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[3, 2].text(-0.2, 1.21, 'C4.', transform=ax[3, 2].transAxes, fontsize=10, va='top', ha='center')\n",
        "\n",
        "cbar_ax = fig.add_axes([0.93, 0.13, 0.01, 0.74])\n",
        "ticks = np.arange(-0.35, 1.25 + 0.2, 0.2)\n",
        "colorbar = fig.colorbar(cntr2_4, cax=cbar_ax, ticks=ticks)\n",
        "colorbar.set_label(label=\"Fraction\", fontsize=10, rotation=270, labelpad=15)\n",
        "\n",
        "plt.savefig('04182025_3x4MonteCarlo.jpeg', dpi=2000)\n",
        "files.download('04182025_3x4MonteCarlo.jpeg')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4/12/2025 Difference between results when N2O_AOA-d18O = 34 versus N2O_AOA-d18O = 46\n",
        "# If not re-running model and plotting N2O fractions (just pulls data from the compiled Google Sheet specified in next line)\n",
        "post_merge = import_sheet_as_df(final_gp16_regression_model, \"9 Final Product Colab\")\n",
        "\n",
        "# Four ODV Plots with potential density as the y-axis\n",
        "# Import necessary packages and functions\n",
        "from matplotlib import tri\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.colab import files\n",
        "\n",
        "# Normalize longitude and depth data before triangulation\n",
        "scaler = MinMaxScaler()\n",
        "scaled_long = scaler.fit_transform(post_merge['LONGITUDE_x'].astype(float).values.reshape(-1,1))\n",
        "scaled_depth = scaler.fit_transform(post_merge['Potdens'].astype(float).values.reshape(-1,1))\n",
        "\n",
        "# Create triangles that are later called in the plot line\n",
        "triang=tri.Triangulation(scaled_long.flatten(), scaled_depth.flatten())\n",
        "triang_analyze=tri.TriAnalyzer(triang)\n",
        "mask=triang_analyze.get_flat_tri_mask()\n",
        "triang.set_mask(mask)\n",
        "\n",
        "def ratio_plot(plot_name, variable, plot_row, plot_column):\n",
        "  '''\n",
        "  Function that takes in the plot title, variable being plotted,\n",
        "  and the position (row/column) of the specific subplot\n",
        "  '''\n",
        "  # Plot data\n",
        "  cntr2 = ax[plot_row,plot_column].tricontourf(post_merge['LONGITUDE_x'].astype(float), post_merge['Potdens'].astype(float), post_merge[variable].astype(float), triangles=triang.triangles, mask=triang.mask,levels=np.linspace(-0.12,0.12,51,endpoint=True), extend=\"neither\", cmap=\"rainbow\", vmin=-0.12, vmax=0.12, fontsize=15)\n",
        "  ax[plot_row,plot_column].plot(post_merge['LONGITUDE_x'].astype(float), post_merge['Potdens'].astype(float), 'ko', markersize=0.5)\n",
        "  ax[plot_row,plot_column].plot(odz_n2o['LONGITUDE_x'].astype(float), odz_n2o['Potdens'].astype(float), 'wx', markersize=2)\n",
        "\n",
        "  # Plot density contours\n",
        "  dens_cntr = ax[plot_row,plot_column].tricontour(post_merge['LONGITUDE_x'].astype(float),post_merge['Potdens'].astype(float),post_merge['Potdens'].astype(float), linewidths=1.0, triangles=triang.triangles, mask=triang.mask,levels=[27, 27.72], colors = \"black\")\n",
        "  ax[plot_row,plot_column].clabel(dens_cntr, inline=True, fontsize=6, manual=[(-123.5, 27), (-123.5, 27.72)])\n",
        "\n",
        "  ax[plot_row,plot_column].set(xlim=(-152.9, -77.1), ylim=(26, 27.9))\n",
        "  ax[plot_row,plot_column].invert_yaxis()\n",
        "  ax[plot_row,plot_column].set_xlabel(\"Longitude (degrees)\", fontsize=11)\n",
        "  ax[plot_row, plot_column].set_ylabel(r\"$\\sigma_{\\Theta}$\", fontsize=11)\n",
        "  ax[plot_row,plot_column].set_title(plot_name, fontsize = 11)\n",
        "  ax[plot_row, plot_column].tick_params(axis='both', which='major', labelsize=11)\n",
        "  return cntr2\n",
        "\n",
        "# Make four plots\n",
        "fig, ax = plt.subplots(2, 2)\n",
        "fig.set_size_inches(14, 5) # Size of the panel\n",
        "fig.subplots_adjust(hspace = 0.6, wspace = 0.25) # Space between plots\n",
        "\n",
        "# Call the function four times for each plot\n",
        "ratio_plot(r\"$\\mathrm{N_2O_{background}}$\", \"Diff Preformed (46 - 34)\", 0, 0)\n",
        "ratio_plot(r\"$\\mathrm{N_2O_{AOA}}$\", \"Diff AOA (46 - 34)\", 0, 1)\n",
        "ratio_plot(r\"$\\mathrm{N_2O_{ID}}$\", \"Diff ID Ratio (46 - 34)\", 1, 0)\n",
        "cntr2_4 = ratio_plot(r\"$\\mathrm{N_2O_{ODZ}}$\", \"Diff ODZ Ratio (46 - 34)\", 1, 1)\n",
        "\n",
        "# Place 'A.' above the top left subplot\n",
        "ax[0, 0].text(0, 1.03, 'A.', transform=ax[0, 0].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "ax[0, 1].text(0, 1.03, 'B.', transform=ax[0, 1].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "ax[1, 0].text(0, 1.03, 'C.', transform=ax[1, 0].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "ax[1, 1].text(0, 1.03, 'D.', transform=ax[1, 1].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "\n",
        "# Colorbar\n",
        "cbar_ax = fig.add_axes([0.93, 0.13, 0.01, 0.74])\n",
        "colorbar = fig.colorbar(cntr2_4, cax=cbar_ax, ticks=np.linspace(-0.12, 0.12, 9))\n",
        "colorbar.set_label(label=\"Fractional Difference\", fontsize=11, rotation=270, labelpad=15)\n",
        "\n",
        "plt.savefig('04182025_46-34diff.jpeg', dpi=2000)\n",
        "files.download('04182025_46-34diff.jpeg')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ENLRxNGYVs3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Original 2 x 2 plot with the four end members and their respective fractions\n",
        "# If not re-running model and plotting N2O fractions (just pulls data from the compiled Google Sheet specified in next line)\n",
        "post_merge = import_sheet_as_df(final_gp16_regression_model, \"10 Final Product Colab\")\n",
        "\n",
        "# Four ODV Plots with potential density as the y-axis\n",
        "# Import necessary packages and functions\n",
        "from matplotlib import tri\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.colab import files\n",
        "\n",
        "# Normalize longitude and depth data before triangulation\n",
        "scaler = MinMaxScaler()\n",
        "scaled_long = scaler.fit_transform(post_merge['LONGITUDE_x'].astype(float).values.reshape(-1,1))\n",
        "scaled_depth = scaler.fit_transform(post_merge['Potdens'].astype(float).values.reshape(-1,1))\n",
        "\n",
        "# Create triangles that are later called in the plot line\n",
        "triang=tri.Triangulation(scaled_long.flatten(), scaled_depth.flatten())\n",
        "triang_analyze=tri.TriAnalyzer(triang)\n",
        "mask=triang_analyze.get_flat_tri_mask()\n",
        "triang.set_mask(mask)\n",
        "\n",
        "def ratio_plot(plot_name, variable, plot_row, plot_column):\n",
        "  '''\n",
        "  Function that takes in the plot title, variable being plotted,\n",
        "  and the position (row/column) of the specific subplot\n",
        "  '''\n",
        "  # Plot data\n",
        "  cntr2 = ax[plot_row,plot_column].tricontourf(post_merge['LONGITUDE_x'].astype(float), post_merge['Potdens'].astype(float), post_merge[variable].astype(float), triangles=triang.triangles, mask=triang.mask,levels=np.linspace(0,1.0000001,51,endpoint=True), extend=\"neither\", cmap=\"rainbow\", vmin=0, vmax=1.0000001, fontsize=15)\n",
        "  ax[plot_row,plot_column].plot(post_merge['LONGITUDE_x'].astype(float), post_merge['Potdens'].astype(float), 'ko', markersize=0.5)\n",
        "  ax[plot_row,plot_column].plot(odz_n2o['LONGITUDE_x'].astype(float), odz_n2o['Potdens'].astype(float), 'wx', markersize=2)\n",
        "\n",
        "  # Plot density contours\n",
        "  dens_cntr = ax[plot_row,plot_column].tricontour(post_merge['LONGITUDE_x'].astype(float),post_merge['Potdens'].astype(float),post_merge['Potdens'].astype(float), linewidths=1.0, triangles=triang.triangles, mask=triang.mask,levels=[27, 27.72], colors = \"black\")\n",
        "  ax[plot_row,plot_column].clabel(dens_cntr, inline=True, fontsize=6, manual=[(-123.5, 27), (-123.5, 27.72)])\n",
        "\n",
        "  ax[plot_row,plot_column].set(xlim=(-152.9, -77.1), ylim=(26, 27.9))\n",
        "  ax[plot_row,plot_column].invert_yaxis()\n",
        "  ax[plot_row,plot_column].set_xlabel(\"Longitude (degrees)\", fontsize=11)\n",
        "  ax[plot_row, plot_column].set_ylabel(r\"$\\sigma_{\\Theta}$\", fontsize=11)\n",
        "  ax[plot_row,plot_column].set_title(plot_name, fontsize = 11)\n",
        "  ax[plot_row, plot_column].tick_params(axis='both', which='major', labelsize=11)\n",
        "  return cntr2\n",
        "\n",
        "# Make four plots\n",
        "fig, ax = plt.subplots(2, 2)\n",
        "fig.set_size_inches(12.5, 4.5) # Size of the panel\n",
        "fig.subplots_adjust(hspace = 0.6, wspace = 0.3) # Space between plots\n",
        "\n",
        "# Call the function four times for each plot\n",
        "ratio_plot(r\"$\\mathrm{N_2O_{background}}$\", \"Preformed Ratio\", 0, 0)\n",
        "ratio_plot(r\"$\\mathrm{N_2O_{AOA}}$\", \"AOA Ratio\", 0, 1)\n",
        "ratio_plot(r\"$\\mathrm{N_2O_{ID}}$\", \"ID Ratio\", 1, 0)\n",
        "cntr2_4 = ratio_plot(r\"$\\mathrm{N_2O_{ODZ}}$\", \"ODZ Ratio\", 1, 1)\n",
        "\n",
        "# Place 'A.' above the top left subplot\n",
        "ax[0, 0].text(0, 1.03, 'A.', transform=ax[0, 0].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "ax[0, 1].text(0, 1.03, 'B.', transform=ax[0, 1].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "ax[1, 0].text(0, 1.03, 'C.', transform=ax[1, 0].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "ax[1, 1].text(0, 1.03, 'D.', transform=ax[1, 1].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "\n",
        "# Colorbar\n",
        "cbar_ax = fig.add_axes([0.93, 0.13, 0.01, 0.74])\n",
        "colorbar = fig.colorbar(cntr2_4, cax=cbar_ax, ticks=np.linspace(0, 1, 6))\n",
        "colorbar.set_label(label=\"Fraction\", fontsize=11, rotation=270, labelpad=20)\n",
        "\n",
        "plt.savefig('04242025_2x2basecase(AOA-d18O = 34).jpeg', dpi=2000)\n",
        "files.download('04242025_2x2basecase(AOA-d18O = 34).jpeg')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c2ifLPsvWJ7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2x2 Plot of four end members and their N2O concentrations instead of fractions\n",
        "# Code uses data from Google Sheet specified in the next line\n",
        "post_merge = import_sheet_as_df(final_gp16_regression_model, \"10 Final Product Colab\")\n",
        "\n",
        "# Four ODV Plots with potential density as the y-axis\n",
        "# Import necessary packages and functions\n",
        "from matplotlib import tri\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.colab import files\n",
        "\n",
        "# Normalize longitude and depth data before triangulation\n",
        "scaler = MinMaxScaler()\n",
        "scaled_long = scaler.fit_transform(post_merge['LONGITUDE_x'].astype(float).values.reshape(-1,1))\n",
        "scaled_depth = scaler.fit_transform(post_merge['Potdens'].astype(float).values.reshape(-1,1))\n",
        "\n",
        "# Create triangles that are later called in the plot line\n",
        "triang=tri.Triangulation(scaled_long.flatten(), scaled_depth.flatten())\n",
        "triang_analyze=tri.TriAnalyzer(triang)\n",
        "mask=triang_analyze.get_flat_tri_mask()\n",
        "triang.set_mask(mask)\n",
        "\n",
        "def ratio_plot(plot_name, variable, plot_row, plot_column):\n",
        "  '''\n",
        "  Function that takes in the plot title, variable being plotted,\n",
        "  and the position (row/column) of the specific subplot\n",
        "  '''\n",
        "  # Plot data\n",
        "  cntr2 = ax[plot_row,plot_column].tricontourf(post_merge['LONGITUDE_x'].astype(float), post_merge['Potdens'].astype(float), post_merge[variable].astype(float), triangles=triang.triangles, mask=triang.mask,levels=np.linspace(0,80,51,endpoint=True), extend=\"neither\", cmap=\"rainbow\", vmin=0, vmax=80, fontsize=15)\n",
        "  ax[plot_row,plot_column].plot(post_merge['LONGITUDE_x'].astype(float), post_merge['Potdens'].astype(float), 'ko', markersize=0.5)\n",
        "  ax[plot_row,plot_column].plot(odz_n2o['LONGITUDE_x'].astype(float), odz_n2o['Potdens'].astype(float), 'wx', markersize=2)\n",
        "\n",
        "  # Plot density contours\n",
        "  dens_cntr = ax[plot_row,plot_column].tricontour(post_merge['LONGITUDE_x'].astype(float),post_merge['Potdens'].astype(float),post_merge['Potdens'].astype(float), linewidths=1.0, triangles=triang.triangles, mask=triang.mask,levels=[27, 27.72], colors = \"black\")\n",
        "  ax[plot_row,plot_column].clabel(dens_cntr, inline=True, fontsize=6, manual=[(-123.5, 27), (-123.5, 27.72)])\n",
        "\n",
        "  ax[plot_row,plot_column].set(xlim=(-152.9, -77.1), ylim=(26, 27.9))\n",
        "  # ax[plot_row,plot_column].set(xlim=(np.min(post_merge['LONGITUDE_x'].astype(float)) - 0.5, np.max(post_merge['LONGITUDE_x'].astype(float))+ 0.5), ylim=(26, 27.9))\n",
        "  ax[plot_row,plot_column].invert_yaxis()\n",
        "  ax[plot_row,plot_column].set_xlabel(\"Longitude (degrees)\", fontsize=11)\n",
        "  ax[plot_row, plot_column].set_ylabel(r\"$\\sigma_{\\Theta}$\", fontsize=11)\n",
        "  ax[plot_row,plot_column].set_title(plot_name, fontsize = 11)\n",
        "  ax[plot_row, plot_column].tick_params(axis='both', which='major', labelsize=11)\n",
        "  return cntr2\n",
        "\n",
        "# Make four plots\n",
        "fig, ax = plt.subplots(2, 2)\n",
        "fig.set_size_inches(12.5, 4.5) # Size of the panel\n",
        "fig.subplots_adjust(hspace = 0.6, wspace = 0.3) # Space between plots\n",
        "\n",
        "# Call the function four times for each plot\n",
        "ratio_plot(r\"$\\mathrm{[N_2O]_{background}}$\", \"Preformed Conc\", 0, 0)\n",
        "ratio_plot(r\"$\\mathrm{[N_2O]_{AOA}}$\", \"AOA Conc\", 0, 1)\n",
        "ratio_plot(r\"$\\mathrm{[N_2O]_{ID}}$\", \"ID Conc\", 1, 0)\n",
        "cntr2_4 = ratio_plot(r\"$\\mathrm{[N_2O]_{ODZ}}$\", \"ODZ Conc\", 1, 1)\n",
        "\n",
        "# Place 'A.' above the top left subplot\n",
        "ax[0, 0].text(0, 1.03, 'A.', transform=ax[0, 0].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "ax[0, 1].text(0, 1.03, 'B.', transform=ax[0, 1].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "ax[1, 0].text(0, 1.03, 'C.', transform=ax[1, 0].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "ax[1, 1].text(0, 1.03, 'D.', transform=ax[1, 1].transAxes, fontsize=11, va='bottom', ha='left')\n",
        "\n",
        "# Colorbar\n",
        "cbar_ax = fig.add_axes([0.93, 0.13, 0.01, 0.74])\n",
        "colorbar = fig.colorbar(cntr2_4, cax=cbar_ax, ticks=np.linspace(0, 80, 9))\n",
        "colorbar.set_label(label=r\"$\\mathrm{[N_2O]}$\", fontsize=11, rotation=270, labelpad=20)\n",
        "\n",
        "plt.savefig('04162025_meanstate.jpeg', dpi=2000)\n",
        "files.download('04162025_meanstate.jpeg')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iMhy2-IMtVxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4x2 Monte Carlo plots where left column is Monte Carlo mean state\n",
        "# right column is the base case - monte carlo mean state\n",
        "# Uses data from Google Sheet specified in next line\n",
        "mc_sheet = import_sheet_as_df(final_gp16_regression_model, \"10 Final Product Colab\")\n",
        "odz_n2o = mc_sheet[(mc_sheet['OXYGEN'].astype(float) < 5) & (mc_sheet['Potdens'].astype(float) > 26.2) & (mc_sheet['Potdens'].astype(float) < 26.8)]\n",
        "\n",
        "from matplotlib import tri\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from google.colab import files\n",
        "\n",
        "# NORMALIZE DATA BEFORE TRIANGULATION\n",
        "scaler = MinMaxScaler()\n",
        "scaled_long = scaler.fit_transform(mc_sheet['LONGITUDE_x'].astype(float).values.reshape(-1,1))\n",
        "scaled_depth = scaler.fit_transform(mc_sheet['Potdens'].astype(float).values.reshape(-1,1))\n",
        "\n",
        "triang=tri.Triangulation(scaled_long.flatten(), scaled_depth.flatten())\n",
        "triang_analyze=tri.TriAnalyzer(triang)\n",
        "mask=triang_analyze.get_flat_tri_mask()\n",
        "triang.set_mask(mask)\n",
        "\n",
        "def mc_plot(plot_name, variable, plot_row, plot_column):\n",
        "  cntr2 = ax[plot_row,plot_column].tricontourf(mc_sheet['LONGITUDE_x'].astype(float),mc_sheet['Potdens'].astype(float),mc_sheet[variable].astype(float), triangles=triang.triangles, mask=triang.mask,levels=np.linspace(-0.35,1.35,51,endpoint=True), extend=\"neither\", cmap=\"rainbow\", vmin=-0.35, vmax=1.35, fontsize=15)\n",
        "  # colorbar = fig.colorbar(cntr2, ax=ax[plot_row,plot_column])\n",
        "\n",
        "  dens_cntr = ax[plot_row,plot_column].tricontour(mc_sheet['LONGITUDE_x'].astype(float),mc_sheet['Potdens'].astype(float),mc_sheet['Potdens'].astype(float), linewidths=0.5, triangles=triang.triangles, mask=triang.mask,levels=[27, 27.72], colors = \"black\")\n",
        "  ax[plot_row,plot_column].plot(mc_sheet['LONGITUDE_x'].astype(float), mc_sheet['Potdens'].astype(float), 'ko', markersize=0.5)\n",
        "  ax[plot_row,plot_column].plot(odz_n2o['LONGITUDE_x'].astype(float), odz_n2o['Potdens'].astype(float), 'wx', markersize=2)\n",
        "  ax[plot_row,plot_column].clabel(dens_cntr, inline=True, fontsize=6, manual=[(-124, 27), (-124, 27.72)])\n",
        "\n",
        "  ax[plot_row,plot_column].set(xlim=(-153, -77), ylim=(26, 28))\n",
        "  ax[plot_row,plot_column].invert_yaxis()\n",
        "  ax[plot_row,plot_column].set_xlabel(\"Longitude (degrees)\", fontsize=10)\n",
        "  ax[plot_row, plot_column].set_ylabel(r\"$\\sigma_{\\Theta}$\", fontsize=10)\n",
        "  ax[plot_row,plot_column].set_title(plot_name, fontsize = 10)\n",
        "  return cntr2\n",
        "\n",
        "fig, ax = plt.subplots(4, 2) # Make twelve plots\n",
        "fig.set_size_inches(13, 10) # Size of the panel\n",
        "fig.subplots_adjust(hspace = 0.8, wspace = 0.5) # Space between plots\n",
        "\n",
        "mc_plot(r\"Monte Carlo Mean State $\\mathrm{N_2O_{background}}$\", \"MC Mean Preformed Ratio\", 0, 0)\n",
        "mc_plot(r\"$\\mathrm{N_2O_{background}}$ - Monte Carlo Mean State $\\mathrm{N_2O_{background}}$\", \"Pre Base Case - Mean State\", 0, 1)\n",
        "\n",
        "mc_plot(r\"Monte Carlo Mean State $\\mathrm{N_2O_{AOA}}$\", \"MC Mean AOA Ratio\", 1, 0)\n",
        "mc_plot(r\"$\\mathrm{N_2O_{AOA}}$ - Monte Carlo Mean State $\\mathrm{N_2O_{AOA}}$\", \"AOA Base Case - Mean State\", 1, 1)\n",
        "\n",
        "mc_plot(r\"Monte Carlo Mean State $\\mathrm{N_2O_{ID}}$\", \"MC Mean ID Ratio\", 2, 0)\n",
        "mc_plot(r\"$\\mathrm{N_2O_{ID}}$ - Monte Carlo Mean State $\\mathrm{N_2O_{ID}}$\", \"ID Base Case - Mean State\", 2, 1)\n",
        "\n",
        "mc_plot(r\"Monte Carlo Mean State $\\mathrm{N_2O_{ODZ}}$\", \"MC Mean CD Ratio\", 3, 0)\n",
        "cntr2_4 = mc_plot(r\"$\\mathrm{N_2O_{ODZ}}$ - Monte Carlo Mean State $\\mathrm{N_2O_{ODZ}}$\", \"CD Base Case - Mean State\", 3, 1)\n",
        "\n",
        "\n",
        "\n",
        "ax[0, 0].text(-0.2, 1.21, 'A1.', transform=ax[0, 0].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[0, 1].text(-0.2, 1.21, 'B1.', transform=ax[0, 1].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[1, 0].text(-0.2, 1.21, 'A2.', transform=ax[1, 0].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[1, 1].text(-0.2, 1.21, 'B2.', transform=ax[1, 1].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[2, 0].text(-0.2, 1.21, 'A3.', transform=ax[2, 0].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[2, 1].text(-0.2, 1.21, 'B3.', transform=ax[2, 1].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[3, 0].text(-0.2, 1.21, 'A4.', transform=ax[3, 0].transAxes, fontsize=10, va='top', ha='center')\n",
        "ax[3, 1].text(-0.2, 1.21, 'B4.', transform=ax[3, 1].transAxes, fontsize=10, va='top', ha='center')\n",
        "\n",
        "cbar_ax = fig.add_axes([0.93, 0.13, 0.01, 0.74])\n",
        "ticks = np.arange(-0.35, 1.25 + 0.2, 0.2)\n",
        "colorbar = fig.colorbar(cntr2_4, cax=cbar_ax, ticks=ticks)\n",
        "colorbar.set_label(label=\"Fraction\", fontsize=10, rotation=270, labelpad=10)\n",
        "\n",
        "plt.savefig('04162025_4x2Supp.jpeg', dpi=2000)\n",
        "files.download('04162025_4x2Supp.jpeg')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aZe4dcjR0Mef"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xUUDyy8GtP0p"
      ],
      "provenance": [],
      "mount_file_id": "1A1PxNPmFabff3FxDwjDkd4KCqT35s-7t",
      "authorship_tag": "ABX9TyPI54M5S+1N8vFEZLKGDFXl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
